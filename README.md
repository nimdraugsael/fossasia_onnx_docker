# Custom ONNX Runtime WASM Build for Browser ML

**FOSS Asia 2026 Talk:** *Deploying ML to Web Browsers: Building a Production Document Corner Detector at <50ms Inference*

This repository contains a reproducible Docker build for creating a **custom, minimal ONNX Runtime WebAssembly** binary. The standard `onnxruntime-web` ships ~12 MB of WASM to support all ~150 ONNX operators. If your model only uses a subset, you can build a stripped runtime — in our case, **2.4 MB (80% reduction)**.

This is a companion artifact for the FOSS Asia 2026 talk. It includes the Dockerfile, build scripts, and annotated code examples from the presentation.

## The Problem

Deploying ML models to web browsers means every byte counts. Users won't wait for a 12 MB WASM download just to run a lightweight model. The standard ONNX Runtime Web includes support for all ~150 ONNX operators, but a typical model uses only 15-25 of them.

## What This Builds

| Output | Size | Use case |
|--------|------|----------|
| `ort-wasm-simd.wasm` | ~2.4 MB | Default — works everywhere, no special headers |
| `ort-wasm-simd.mjs` | ~11 KB | JS loader for non-threaded build |
| `ort-wasm-simd-threaded.wasm` | ~2.4 MB | Faster — needs `SharedArrayBuffer` (COOP/COEP headers) |
| `ort-wasm-simd-threaded.mjs` | ~18 KB | JS loader for threaded build |

## Quick Start

### Use pre-built image

```bash
mkdir -p output
docker pull ghcr.io/nimdraugsael/fossasia_onnx_docker:latest
docker run --rm -v $(pwd)/output:/output ghcr.io/nimdraugsael/fossasia_onnx_docker:latest
ls -lh output/
```

### Build from source

```bash
docker build -t ort-wasm-custom .
mkdir -p output
docker run --rm -v $(pwd)/output:/output ort-wasm-custom
```

Build takes ~30-40 minutes and needs ~8 GB RAM.

## About BlazeDOC

The model used as the reference case is **BlazeDOC** — a lightweight document corner detector for KYC (Know Your Customer) verification flows. It detects 4 corners of an ID document in a camera feed, running entirely client-side in the browser.

**Key numbers:**
- **270K parameters** (0.27M) — inspired by Google's BlazeFace architecture
- **1.4 MB** ONNX model (FP32)
- **~5 ms** inference on desktop CPU (ONNX Runtime native)
- **~55 ms** inference in browser WASM (single-threaded, SIMD)
- **93% PCK@5px** accuracy on confident detections (MIDV-500 dataset)

**Architecture:**
```
Input: 416x416x3
  -> Backbone (BlazeFace-style depthwise separable convolutions)  -> 13x13x96
  -> Upsampling Neck (ConvTranspose2d x3)                         -> 104x104x32
  -> Heatmap Head (Conv + Sigmoid)                                -> 104x104x4
  -> ONNX Wrapper (argmax + coordinate extraction)                -> corners (4,2) + scores (4)
```

## Pinned Versions

Everything is pinned for reproducibility:

| Component | Version | Pin method |
|-----------|---------|------------|
| Ubuntu base | 22.04 | Docker digest SHA |
| ONNX Runtime | main@`34b7558e` | Exact git commit |
| Emscripten (emsdk) | 4.0.11 | Version string |
| Python | 3.10.6 | APT version |
| CMake | 4.1.2 | pip `==` (ORT 1.24+ needs cmake >= 3.28) |
| NumPy | 2.2.6 | pip `==` |
| FlatBuffers | 25.9.23 | pip `==` |
| Protobuf | 5.29.4 | pip `==` |

> **Why so many pins?** ORT doesn't document compatible build dependency versions. These exact combinations were found through extensive trial-and-error. Changing any single version may break the build.

## The 19 Operators

From `required_operators.config`, generated by converting the model to ORT format:

```
Math:       Div, Mul, Sub
Activation: Relu
Neural:     Conv, ConvTranspose
Tensor:     Reshape, Concat, Squeeze, Unsqueeze, ArgMax, Cast, GatherElements
Logic:      Equal, Not, And, Mod, Sign
Extension:  com.microsoft.FusedConv (fused Conv+BN+ReLU)
```

## SIMD-only vs. Threaded: When to Use Which

| | SIMD-only | SIMD + Threads |
|---|-----------|----------------|
| Size | 2.4 MB | 2.4 MB |
| Performance | Good (single-core) | Better (multi-core) |
| Browser support | Chrome 91+, FF 89+, Safari 15+ | Same + SharedArrayBuffer |
| CORS headers | None required | `COEP: require-corp`, `COOP: same-origin` |
| Iframe support | Yes | No (blocked by iframe policies) |

We ship SIMD-only as default because our app runs inside iframes (widget mode) where `SharedArrayBuffer` is not available.

## Code Examples

The `examples/` directory contains annotated code snippets from the talk:

| File | Description |
|------|-------------|
| [`blazeblock.py`](examples/blazeblock.py) | BlazeDOC model architecture — BlazeBlock + detector |
| [`awing_loss.py`](examples/awing_loss.py) | Adaptive Wing Loss (ICCV 2019) for heatmap regression |
| [`onnx_wrapper.py`](examples/onnx_wrapper.py) | Embedding post-processing (argmax) into the ONNX graph |
| [`wasm_build.sh`](examples/wasm_build.sh) | Build command with flag explanations |
| [`browser_detector.ts`](examples/browser_detector.ts) | Browser-side detection with ONNX Runtime Web |
| [`vite_wasm.ts`](examples/vite_wasm.ts) | Vite plugin for serving WASM/ONNX files correctly |

These are illustrative snippets, not runnable as-is — they show the key patterns discussed in the talk.

## How to Adapt for Your Own Model

1. **Convert your model to ORT format:**
   ```bash
   python -m onnxruntime.tools.convert_onnx_models_to_ort your_model.onnx
   ```
   This outputs a `required_operators_and_types.config` file listing all operators your model uses.

2. **Replace `required_operators.config`** with your generated config.

3. **Rebuild:**
   ```bash
   docker build -t my-custom-ort .
   mkdir -p output
   docker run --rm -v $(pwd)/output:/output my-custom-ort
   ```

4. **Use in your app:**
   ```typescript
   import * as ort from "onnxruntime-web/wasm";
   ort.env.wasm.wasmPaths = "/path/to/your/custom-wasm/";
   ```

## Three Key Decisions (Talk Structure)

The talk covers three engineering decisions for deploying ML to browsers:

1. **Architecture Choice: BlazeFace for Documents** — Why 5x5 depthwise separable convolutions give the best accuracy-to-compute ratio on mobile GPUs (same FLOPs as two 3x3, fewer memory reads).

2. **Heatmap Regression over Direct Coordinates** — Why predicting 4 Gaussian heatmaps (104x104) with Adaptive Wing Loss produces more stable training and sub-pixel corner precision vs. directly regressing 8 coordinate values.

3. **Custom WASM Build (80% Size Reduction)** — How to build ONNX Runtime from source with only the operators your model needs, achieving 12 MB -> 2.4 MB reduction.

## References

- [BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs](https://arxiv.org/abs/1907.05047) (Bazarevsky et al., 2019)
- [Adaptive Wing Loss for Robust Face Alignment via Heatmap Regression](https://arxiv.org/abs/1904.07399) (Wang et al., ICCV 2019)
- [MIDV-500: A Dataset for Identity Document Analysis and Recognition](https://arxiv.org/abs/1807.05786) (Arlazarov et al., 2018)
- [ONNX Runtime Web](https://onnxruntime.ai/docs/tutorials/web/)
- [ONNX Runtime Reduced Operator Builds](https://onnxruntime.ai/docs/build/custom.html)

## License

MIT
